{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/OSDA_Generator\n"
     ]
    }
   ],
   "source": [
    "# Change to the top directory\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from ddc_pub import ddc_v3 as ddc\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "data = pd.read_excel('data/Jensen_et_al_CentralScience_OSDA_Zeolite_data.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our featurization for the zeolite structures and synthesis conditions\n",
    "# zeolites are featurized with structural features taken from IZA (http://www.iza-structure.org/)\n",
    "def featurize_zeolite(row):\n",
    "    features = [row['FD'], row['max_ring_size'], row['channel_dim'], row['inc_vol'], row['accvol'], row['maxarea'], row['minarea']]\n",
    "    if any([pd.isnull(x) for x in features]):\n",
    "        # Several structures without official IZA designations will not have complete data\n",
    "        # and therefore are removed from the data ie ITQ-21, ITQ-43, SU-74, etc\n",
    "        print('Problem: ', row['Code'], 'Missing Information in Data')\n",
    "        return None\n",
    "    else:\n",
    "        return features\n",
    "# synthesis conditions are one encoded based on the most common elements encountered\n",
    "def featurize_synthesis(row):\n",
    "    seeds = ['seed', 'SAPO-56 seeds', 'SSZ-57', 'FAU', 'seeded with magadiite', 'seeds']\n",
    "    solvents = ['ethylene glycol', 'hexanol', '2-propanol', 'triethylene glycol', 'triglycol',\n",
    "                'polyethylene glycol', 'n-hexanol', 'glycol', 'propane-1,3-diol', 'butanol', \n",
    "                'glycerol', 'isobutylamine', 'tetraethylene glycol', '1-hexanol', \n",
    "               'sec-butanol', 'iso-butanol', 'ethylene glycol monomethyl ether', 'ethanol']\n",
    "    acids = ['H2SO4', 'acetic acid', 'oxalic acid', 'succinic acid', 'arsenic acid', 'HNO3', 'HCl',\n",
    "            'SO4']\n",
    "    frameworks = ['Co', 'Mn', 'Cu', 'Zn', 'Cd', 'Cr', 'V', 'Ce', 'Nd', 'Sn', 'Zr', 'Ni',\n",
    "                  'S', 'Sm', 'Dy', 'Y', 'La', 'Gd', 'In', 'Nb', 'Te', 'As', 'Hf', 'W',\n",
    "                 'Se']\n",
    "    common_frameworks = ['Si', 'Al', 'P', 'Ge', 'B', 'Ti', 'Ga', 'Fe']\n",
    "    cations = ['Mg', 'Rb', 'Li', 'Cs', 'Sr', 'Ba', 'Be', 'Ca']\n",
    "    common_cations = ['Na', 'K']\n",
    "    bad = ['pictures', 'need access', 'also called azepane', 'SMILES code']\n",
    "    syns = [x.strip() for x in [row['syn1'], row['syn2'], row['syn3'], row['syn4'], row['syn5'],\n",
    "                       row['syn6'], row['syn7'], row['syn8']] if not pd.isnull(x)]\n",
    "    if not syns:\n",
    "        return None\n",
    "    syn_vector = []\n",
    "    for c in common_frameworks:\n",
    "        if c in syns:\n",
    "            syn_vector.append(1)\n",
    "        else:\n",
    "            syn_vector.append(0)\n",
    "    for c in common_cations:\n",
    "        if c in syns:\n",
    "            syn_vector.append(1)\n",
    "        else:\n",
    "            syn_vector.append(0)\n",
    "    if 'F' in syns:\n",
    "        syn_vector.append(1)\n",
    "    else:\n",
    "        syn_vector.append(0)\n",
    "    frame, cat, seed, solv, acid, oth = 0,0,0,0,0,0\n",
    "    for s in syns:\n",
    "        if s in frameworks:\n",
    "            frame = 1\n",
    "        elif s in cations:\n",
    "            cat = 1\n",
    "        elif s in seeds:\n",
    "            seed = 1\n",
    "        elif s in solvents:\n",
    "            solv = 1\n",
    "        elif s in acids:\n",
    "            acid = 1\n",
    "        elif s.count(' ') < 2 and s not in bad and len(s) > 2:\n",
    "            oth = 1\n",
    "    syn_vector.extend([frame, cat, seed, solv, acid, oth])\n",
    "    return syn_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  NUD-1 Missing Information in Data\n",
      "Problem:  NUD-1 Missing Information in Data\n",
      "Problem:  NUD-1 Missing Information in Data\n",
      "Problem:  NUD-1 Missing Information in Data\n",
      "Problem:  NUD-1 Missing Information in Data\n",
      "Problem:  NUD-1 Missing Information in Data\n",
      "Problem:  ASU-14 Missing Information in Data\n",
      "Problem:  ASU-16 Missing Information in Data\n",
      "Problem: [Na+].CCCCCCCCCCCCO[S]([O-])(=O)=O could not be randomized\n",
      "Problem:  SU-74 Missing Information in Data\n",
      "Problem:  SU-74 Missing Information in Data\n",
      "Problem:  SU-M Missing Information in Data\n",
      "Problem:  SU-MB Missing Information in Data\n",
      "Problem:  SU-MB Missing Information in Data\n",
      "Problem:  SU-74 Missing Information in Data\n",
      "Problem:  nan Missing Information in Data\n",
      "Problem:  ITQ-43 Missing Information in Data\n",
      "Problem:  ITQ-43 Missing Information in Data\n",
      "Problem:  ITQ-43 Missing Information in Data\n",
      "Problem:  ITQ-43 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  SU-77 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  NUD-1 Missing Information in Data\n",
      "Problem:  NUD-1 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  SU-74 Missing Information in Data\n",
      "Problem:  SU-74 Missing Information in Data\n",
      "Problem: NCNCNCNCN.[Cu+2] could not be randomized\n",
      "Problem:  ITQ-43 Missing Information in Data\n",
      "Problem: C(CNCCNCCNCCNCCN)N.[Ni+2] could not be randomized\n",
      "Problem: NCNCNCNCN.[Cu+2] could not be randomized\n",
      "Problem:  nan Missing Information in Data\n",
      "Problem:  nan Missing Information in Data\n",
      "Problem: NCNCNCNCN.[Cu+2] could not be randomized\n",
      "Problem: [NH4+].CC([O-])=O could not be randomized\n",
      "Problem: [NH4+].[NH4+].[O-]C(=O)C([O-])=O could not be randomized\n",
      "Problem: C(=O)(O)[O-].[NH4+] could not be randomized\n",
      "Problem: [NH4+].CC([O-])=O could not be randomized\n",
      "Problem: [NH4+].CC([O-])=O could not be randomized\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-43 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-43 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-43 Missing Information in Data\n",
      "Problem: NCCNCCN.c1ccncc1 could not be randomized\n",
      "Problem:  ASU-16 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-43 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-43 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ITQ-43 Missing Information in Data\n",
      "Problem:  ITQ-21 Missing Information in Data\n",
      "Problem:  ASU-16 Missing Information in Data\n",
      "Problem:  Quartz Missing Information in Data\n",
      "Problem:  Quartz Missing Information in Data\n",
      "Problem:  ASU-12 Missing Information in Data\n",
      "Problem:  SU-12 Missing Information in Data\n",
      "179835 (179835, 7) (179835, 17) 179835\n"
     ]
    }
   ],
   "source": [
    "# featurize and augment the data\n",
    "smiles, zeolites, synthesis, codes = [],[],[],[]\n",
    "# Whether or not to augment the data with smiles string randomization\n",
    "augment = True\n",
    "for i, row in data.iterrows():\n",
    "    if ' + ' not in row['smiles']: # only look at single-template synthesis\n",
    "        zeo = featurize_zeolite(row=row)\n",
    "        syn = featurize_synthesis(row=row)\n",
    "        if zeo is not None and syn is not None:\n",
    "            if augment:\n",
    "                new_smiles = []\n",
    "                m = Chem.MolFromSmiles(row['smiles'])\n",
    "                for i in range(100): # randomize smiles string up to 100 times\n",
    "                    try:\n",
    "                        rand_smile = Chem.MolToSmiles(m, canonical=False, doRandom=True, isomericSmiles=False)\n",
    "                        rand_mol = Chem.MolFromSmiles(rand_smile)\n",
    "                        if m is not None and rand_smile not in new_smiles:\n",
    "                            new_smiles.append(rand_smile)\n",
    "                    except:\n",
    "                        print('Problem:', row['smiles'], 'could not be randomized')\n",
    "                        break\n",
    "                for smile in new_smiles:\n",
    "                    smiles.append(smile)\n",
    "                    zeolites.append(zeo)\n",
    "                    synthesis.append(syn)\n",
    "                    codes.append(row['Code'])\n",
    "            else:\n",
    "                smiles.append(row['smiles'])\n",
    "                zeolites.append(zeo)\n",
    "                synthesis.append(syn)\n",
    "                codes.append(row['Code'])\n",
    "zeolites = np.array(zeolites)\n",
    "synthesis = np.array(synthesis)\n",
    "print(len(smiles), zeolites.shape, synthesis.shape, len(codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179613 (179613, 7) (179613, 17) 179613\n"
     ]
    }
   ],
   "source": [
    "# Need to clean the OSDAs to remove unusual characters\n",
    "chars = set()\n",
    "for s in smiles:\n",
    "    if 'Si' in s:\n",
    "        continue\n",
    "    for c in s:\n",
    "        chars.add(c)\n",
    "chars = list(chars)\n",
    "cant = ['a', 't', ' ', 'i', 'd', 'e', 'f', 'y']\n",
    "new_smile, new_z, new_s, new_c = [],[],[],[]\n",
    "for s, z, d, c in zip(smiles, zeolites, synthesis, codes):\n",
    "    if 'Si' in s:\n",
    "        continue\n",
    "    found = False\n",
    "    for c in s:\n",
    "        if c in cant:\n",
    "            found = True\n",
    "    if not found:\n",
    "        new_z.append(z)\n",
    "        new_s.append(d)\n",
    "        new_smile.append(s)\n",
    "        new_c.append(c)\n",
    "smiles = new_smile\n",
    "codes = new_c\n",
    "zeolites = np.array(new_z)\n",
    "synthesis = np.array(new_s)\n",
    "print(len(smiles), zeolites.shape, synthesis.shape, len(codes))\n",
    "chars = \"\".join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179613, 7)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the zeolite vectors\n",
    "zeo_norm = pickle.load(open('models/zeolite_normalizer.pkl', 'rb'))\n",
    "zeolites = zeo_norm.transform(zeolites)\n",
    "print(zeolites.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73913\n",
      "73913\n",
      "14783\n",
      "36878\n",
      "142735 142735 (142735, 7) (142735, 17)\n",
      "51661 36878 (36878, 7) (36878, 17)\n",
      "(142735, 24) (36878, 24)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "split =  \"random\" # options are None, random, or zeolite (ie CHA or SFW)\n",
    "train_smiles, train_zeolites, train_synthesis, train_codes = [],[],[],[]\n",
    "test_smiles, test_zeolites, test_synthesis, test_codes = [],[],[],[]\n",
    "train_input, test_input = [],[]\n",
    "if split is None:\n",
    "    train_smiles = smiles\n",
    "    train_zeolites = zeolites\n",
    "    train_synthesis = synthesis\n",
    "    train_codes = codes\n",
    "    for z, syn in zip(zeolites, synthesis):\n",
    "        train_input.append(list(z)+list(syn))\n",
    "elif split == 'random':\n",
    "    unique_smiles = list(np.unique(smiles))\n",
    "    print(len(unique_smiles))\n",
    "    test_indices = []\n",
    "    random.shuffle(unique_smiles)\n",
    "    print(len(unique_smiles))\n",
    "    test_smiles = unique_smiles[:round(0.2*len(unique_smiles))] # 20% held out set\n",
    "    print(len(test_smiles))\n",
    "    for t in test_smiles:\n",
    "        for i, s in enumerate(smiles):\n",
    "            if t == s:\n",
    "                test_indices.append(i)\n",
    "    print(len(test_indices))\n",
    "    for i, (s, z, syn, c) in enumerate(zip(smiles, zeolites, synthesis, codes)):\n",
    "        if i in test_indices:\n",
    "            test_smiles.append(s)\n",
    "            test_zeolites.append(z)\n",
    "            test_synthesis.append(syn)\n",
    "            test_codes.append(c)\n",
    "            test_input.append(list(z)+list(syn))\n",
    "        else:\n",
    "            train_smiles.append(s)\n",
    "            train_zeolites.append(z)\n",
    "            train_synthesis.append(syn)\n",
    "            train_codes.append(c)\n",
    "            train_input.append(list(z)+list(syn))\n",
    "else:\n",
    "    if split not in unique_codes:\n",
    "        print('Problem:', split, 'not a zeolite in the data')\n",
    "    else:\n",
    "        for i, (s, z, syn, c) in enumerate(zip(smiles, zeolites, synthesis_codes)):\n",
    "            if split == c:\n",
    "                test_smiles.append(s)\n",
    "                test_zeolites.append(z)\n",
    "                test_synthesis.append(syn)\n",
    "                test_codes.append(c)\n",
    "                test_input.append(list(z)+list(syn))\n",
    "            else:\n",
    "                train_smiles.append(s)\n",
    "                train_zeolites.append(z)\n",
    "                train_synthesis.append(syn)\n",
    "                train_codes.append(c)\n",
    "                train_input.append(list(z)+list(syn))\n",
    "train_zeolites = np.array(train_zeolites)\n",
    "train_synthesis = np.array(train_synthesis)\n",
    "test_zeolites = np.array(test_zeolites)\n",
    "test_synthesis = np.array(test_synthesis)\n",
    "train_input = np.array(train_input)\n",
    "test_input = np.array(test_input)\n",
    "print(len(train_smiles), len(train_codes), train_zeolites.shape, train_synthesis.shape)\n",
    "print(len(test_smiles), len(test_codes), test_zeolites.shape, test_synthesis.shape)\n",
    "print(train_input.shape, test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142735\n"
     ]
    }
   ],
   "source": [
    "# convert training smiles to binary\n",
    "mol_train = [Chem.rdchem.Mol.ToBinary(Chem.MolFromSmiles(x)) for x in train_smiles]\n",
    "mol_train = np.array(mol_train)\n",
    "print(len(mol_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "C1(N)2[n+]c34PO=HlF-567S\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "# Need to pass in set of possible characters and max len of smiles\n",
    "charset = ''\n",
    "for x in train_smiles:\n",
    "    for i in x:\n",
    "        if i not in charset:\n",
    "            charset = charset+i\n",
    "print(len(charset))\n",
    "print(charset)\n",
    "max_len = 0\n",
    "for x in train_smiles:\n",
    "    if len(x) > max_len:\n",
    "        max_len = len(x)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model in train mode.\n",
      "Input type is 'molecular descriptors'.\n",
      "Model received 128461 train samples and 14274 validation samples.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Latent_Input (InputLayer)       [(None, 24)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Inputs (InputLayer)     [(None, 132, 27)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "latent_to_states_model (Model)  [(None, 256), (None, 44544       Latent_Input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_model (Model)             (None, 132, 27)      1354523     Decoder_Inputs[0][0]             \n",
      "                                                                 latent_to_states_model[1][0]     \n",
      "                                                                 latent_to_states_model[1][1]     \n",
      "                                                                 latent_to_states_model[1][2]     \n",
      "                                                                 latent_to_states_model[1][3]     \n",
      "                                                                 latent_to_states_model[1][4]     \n",
      "                                                                 latent_to_states_model[1][5]     \n",
      "==================================================================================================\n",
      "Total params: 1,399,067\n",
      "Trainable params: 1,394,459\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dataset_info = dict()\n",
    "dataset_info['maxlen'] = max_len\n",
    "dataset_info['charset'] = charset\n",
    "dataset_info['name'] = 'OSDA_model'\n",
    "model = ddc.DDC(x=np.array(list(train_input)),\n",
    "                y=mol_train,\n",
    "                scaling=False,\n",
    "                pca=False,\n",
    "                dec_layers=3,\n",
    "                code_layer_dim=128,\n",
    "                batch_size=128,\n",
    "                dataset_info=dataset_info\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "\n",
      "Model trained with dataset OSDA_model that has maxlen=128 and charset=C1(N)2[n+]c34PO=HlF-567S for 100 epochs.\n",
      "noise_std: 0.010000, lstm_dim: 256, dec_layers: 3, td_dense_dim: 0, batch_size: 128, codelayer_dim: 24, lr: 0.001000.\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 1/1000\n",
      "101/100 [==============================] - 25s 250ms/step - loss: 0.4892 - val_loss: 0.2566\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 2/1000\n",
      "101/100 [==============================] - 19s 189ms/step - loss: 0.2169 - val_loss: 0.2053\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 3/1000\n",
      "101/100 [==============================] - 20s 197ms/step - loss: 0.1799 - val_loss: 0.1873\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 4/1000\n",
      " 37/100 [==========>...................] - ETA: 11s - loss: 0.1644"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6ead621d6470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0msch_lr_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0msch_lr_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bin/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m            )\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/ddc_pub/ddc_v3.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, mini_epochs, patience, model_name, gpus, workers, use_multiprocessing, verbose, max_queue_size, clipvalue, save_period, checkpoint_dir, lr_decay, sch_epoch_to_start, sch_last_epoch, sch_lr_init, sch_lr_final)\u001b[0m\n\u001b[1;32m   1014\u001b[0m                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             )  # 1 to show progress bar\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m               training=training))\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_branch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_update\u001b[0;34m(self, updates, inputs)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m             \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mmean_update\u001b[0;34m()\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0mtrue_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_do_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoving_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mfalse_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoving_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_branch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mvariance_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m     58\u001b[0m   return smart_module.smart_cond(\n\u001b[0;32m---> 59\u001b[0;31m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mmean_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0mtrue_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_do_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoving_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0mfalse_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoving_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_branch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_do_update\u001b[0;34m(var, value)\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;34m\"\"\"Compute the updates for mean and variance.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         return self._assign_moving_average(var, value, self.momentum,\n\u001b[0;32m--> 756\u001b[0;31m                                            inputs_size)\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mmean_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_assign_moving_average\u001b[0;34m(self, variable, value, momentum, inputs_size)\u001b[0m\n\u001b[1;32m    476\u001b[0m           update_delta = array_ops.where(inputs_size > 0, update_delta,\n\u001b[1;32m    477\u001b[0m                                          K.zeros_like(update_delta))\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_assign_new_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign_sub\u001b[0;34m(ref, value, use_locking, name)\u001b[0m\n\u001b[1;32m    162\u001b[0m     return gen_state_ops.assign_sub(\n\u001b[1;32m    163\u001b[0m         ref, value, use_locking=use_locking, name=name)\n\u001b[0;32m--> 164\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign_sub\u001b[0;34m(self, delta, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    755\u001b[0m       assign_sub_op = gen_resource_variable_ops.assign_sub_variable_op(\n\u001b[1;32m    756\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_sub_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/osda_env/lib/python3.6/site-packages/tensorflow_gpu-2.0.0-py3.6-linux-x86_64.egg/tensorflow_core/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_sub_variable_op\u001b[0;34m(resource, value, name)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;34m\"AssignSubVariableOp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         value)\n\u001b[0m\u001b[1;32m    117\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(epochs=100, \n",
    "            lr=1e-3,\n",
    "            mini_epochs=10,\n",
    "            patience=25,\n",
    "            model_name='OSDA_model',\n",
    "            verbose=1,\n",
    "            save_period=50,\n",
    "            lr_decay=True, \n",
    "            sch_epoch_to_start=500,\n",
    "            sch_lr_init=1e-3,\n",
    "            sch_lr_final=1e-6,\n",
    "            checkpoint_dir='bin/'\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n",
      "Elapsed time: 0.402 seconds.\n"
     ]
    }
   ],
   "source": [
    "model.save('models/OSDA_model_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osda_gen",
   "language": "python",
   "name": "osda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
